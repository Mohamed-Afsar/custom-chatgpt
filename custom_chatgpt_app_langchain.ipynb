{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61fd8d9c-62ff-41ec-a811-901add3c27e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "load_dotenv(find_dotenv(), override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d9a939d-25ff-41ec-8105-b74e617b97f4",
   "metadata": {},
   "source": [
    "# Custom ChatGPT app with Langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2dbe1d90-ea4e-4f89-acf4-2b6d382df723",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Your prompt:  Capital of India is ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The capital of India is New Delhi.\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Your prompt:  Its population ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Are you referring to the population of a specific place or country? Could you please provide more context or specify your question?\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Your prompt:  quit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Goodbye!\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import SystemMessage\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import ChatPromptTemplate, HumanMessagePromptTemplate\n",
    "\n",
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=1)\n",
    "\n",
    "prompt = ChatPromptTemplate(\n",
    "    input_variables=['content'],\n",
    "    messages=[\n",
    "        SystemMessage(content=\"You are a chatbot having a conversation with a human.\"),\n",
    "        HumanMessagePromptTemplate.from_template('{content}')\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=prompt,\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "while True:\n",
    "    content = input(\"Your prompt: \")\n",
    "    if content in ['quit', 'exit', 'bye']:\n",
    "        print('Goodbye!')\n",
    "        break\n",
    "\n",
    "    response = chain.run(\n",
    "        {'content': content}\n",
    "    )\n",
    "    print(response)\n",
    "    print('-' * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e546e90-0666-4d41-8658-c038c585976d",
   "metadata": {},
   "source": [
    "### Adding Chat memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3139092a-f8f4-4057-993b-a301f1ac44fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Your prompt:  Is it a good brand?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FILA is widely regarded as a good brand in terms of both quality and style. It has a long-standing reputation in the sportswear industry and its products are known for their durability and functionality. FILA's designs often blend sport and fashion, making them popular among both athletes and those seeking trendy casual wear. The brand regularly collaborates with influential designers and celebrities, further solidifying its status as a trusted and fashionable choice. However, personal opinions on brands can vary, so it's always recommended to do your own research and try out the products for yourself to determine if they align with your preferences and needs.\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from langchain.memory import ConversationBufferMemory, FileChatMessageHistory\n",
    "from langchain.prompts import MessagesPlaceholder\n",
    "\n",
    "history = FileChatMessageHistory('chat_history.json')\n",
    "\n",
    "memory = ConversationBufferMemory(\n",
    "    memory_key='chat_history',\n",
    "    chat_memory=history,\n",
    "    return_messages=True\n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate(\n",
    "    input_variables=['content'],\n",
    "    messages=[\n",
    "        SystemMessage(content=\"You are a chatbot having a conversation with a human.\"),\n",
    "        MessagesPlaceholder(\n",
    "            variable_name='chat_history'\n",
    "        ), # Where the memory will be stored\n",
    "        HumanMessagePromptTemplate.from_template('{content}')\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=prompt,\n",
    "    memory=memory,\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "while True:\n",
    "    content = input(\"Your prompt: \")\n",
    "    if content in ['quit', 'exit', 'bye']:\n",
    "        print('Goodbye!')\n",
    "        break\n",
    "\n",
    "    response = chain.run(\n",
    "        {'content': content}\n",
    "    )\n",
    "    print(response)\n",
    "    print('-' * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c486daa-a31f-4dad-885d-120ee604b96c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
